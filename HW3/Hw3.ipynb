{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fead65c8-5843-4165-9ad5-3b2d48657294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482ce0d-cbac-4913-b6ee-b3b8b9a22432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e5590e-028e-481c-be65-37131050345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('spoken_train-v1.1.json', 'rb') as f:\n",
    "  squad = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2145edb0-8d15-4dbd-830a-d949ef1609a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'paragraphs'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad['data'][0].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d3e9100-9113-42c7-95e2-de86ea87c6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):  \n",
    "  # load the json file\n",
    "  with open(path, 'rb') as f:\n",
    "    squad = json.load(f)\n",
    "\n",
    "  contexts = []\n",
    "  questions = []\n",
    "  answers = []\n",
    "\n",
    "  for group in squad['data']:\n",
    "    for passage in group['paragraphs']:\n",
    "      context = passage['context']\n",
    "      for qa in passage['qas']:\n",
    "        question = qa['question']\n",
    "        for answer in qa['answers']:\n",
    "          contexts.append(context)\n",
    "          questions.append(question)\n",
    "          answers.append(answer)\n",
    "\n",
    "  return contexts, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c47587-6f28-4e2b-ac0a-b1d272d876eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2f03380-6528-4449-93fb-e0bc27871318",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_contexts, train_questions, train_answers = read_data('spoken_train-v1.1.json')\n",
    "valid_contexts, valid_questions, valid_answers = read_data('spoken_test-v1.1.json')\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8725681c-e7b1-4a45-b0f6-9f3327f96bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What did Hermann Ebbinghaus study?\n",
      "{'answer_start': 406, 'text': 'memory studies', 'answer_end': 420}\n"
     ]
    }
   ],
   "source": [
    "print(train_questions[-14000])\n",
    "print(train_answers[-14000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abeba359-9954-4c9b-9ba0-168ff861f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_end_idx(answers, contexts):\n",
    "  for answer, context in zip(answers, contexts):\n",
    "    gold_text = answer['text']\n",
    "    start_idx = answer['answer_start']\n",
    "    end_idx = start_idx + len(gold_text)\n",
    "\n",
    "    # sometimes squad answers are off by a character or two so we fix this\n",
    "    if context[start_idx:end_idx] == gold_text:\n",
    "      answer['answer_end'] = end_idx\n",
    "    elif context[start_idx-1:end_idx-1] == gold_text:\n",
    "      answer['answer_start'] = start_idx - 1\n",
    "      answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n",
    "    elif context[start_idx-2:end_idx-2] == gold_text:\n",
    "      answer['answer_start'] = start_idx - 2\n",
    "      answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n",
    "\n",
    "add_end_idx(train_answers, train_contexts)\n",
    "add_end_idx(valid_answers, valid_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "49898629-fa89-4040-916c-3ca2bac9ae34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What did Hermann Ebbinghaus study?\n",
      "{'answer_start': 406, 'text': 'memory studies', 'answer_end': 420}\n"
     ]
    }
   ],
   "source": [
    "print(train_questions[-14000])\n",
    "print(train_answers[-14000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e5c7023-a3cc-4838-9570-0a9177906d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizerFast\n",
    "\n",
    "# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
    "# valid_encodings = tokenizer(valid_contexts, valid_questions, truncation=True, padding=True)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8650dab-dd72-42a4-ab51-13d2322669ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "doc_stride = 128  # Set the doc stride value as per your requirements\n",
    "train_encodings = tokenizer(\n",
    "    train_contexts,\n",
    "    train_questions,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=250,\n",
    "    stride=doc_stride\n",
    ")\n",
    "valid_encodings = tokenizer(\n",
    "    valid_contexts,\n",
    "    valid_questions,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=250,\n",
    "    stride=doc_stride\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df8b5451-f286-4b76-af29-e4b01cf7a341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7ad6796-735c-485c-bf5e-d0483dc5558e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37111 context-question pairs in training dataset\n",
      "There are 15875 context-question pairs in testing dataset\n"
     ]
    }
   ],
   "source": [
    "no_of_encodings = len(train_encodings['input_ids'])\n",
    "no_of_valid_encodings = len(valid_encodings['input_ids'])\n",
    "print(f'There are {no_of_encodings} context-question pairs in training dataset')\n",
    "print(f'There are {no_of_valid_encodings} context-question pairs in testing dataset')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c04eae36-9795-4dcd-9969-40d1406e5ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs:  [101, 3565, 4605, 5595, 2001, 2019, 2137, 2374, 2208, 2000, 5646, 1996, 3410, 1997, 1996, 2120, 2374, 2223, 5088, 2005, 1996, 3174, 5417, 2161, 1012, 1996, 2137, 2374, 3034, 1037, 1042, 1039, 1039, 3410, 7573, 14169, 3249, 1996, 2120, 2374, 3034, 1050, 1042, 1039, 1039, 3410, 3792, 12915, 3174, 2176, 2000, 2702, 2000, 7796, 2037, 2353, 3565, 4605, 2516, 1012, 1996, 2208, 2001, 2209, 2006, 2337, 5066, 3174, 7032, 1998, 11902, 2015, 3346, 1999, 1996, 2624, 3799, 3016, 2181, 4203, 10254, 2662, 1012, 2004, 2023, 2001, 1996, 10882, 6199, 2666, 2705, 3565, 4605, 1996, 2223, 13155, 1996, 3585, 5315, 2007, 2536, 25507, 2015, 11107, 2004, 2092, 2004, 8184, 28324, 2075, 1996, 4535, 1997, 10324, 2169, 3565, 4605, 2208, 2007, 3142, 16371, 28990, 2015, 2104, 2029, 2027, 5114, 2052, 2031, 2042, 2124, 2004, 3565, 4605, 1048, 5271, 2008, 1996, 8154, 2071, 14500, 2956, 1996, 5640, 16371, 28990, 2015, 5595, 1012, 102, 2029, 5088, 2136, 3421, 1996, 10511, 2012, 3565, 4605, 2753, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Tokens:  ['[CLS]', 'super', 'bowl', 'fifty', 'was', 'an', 'american', 'football', 'game', 'to', 'determine', 'the', 'champion', 'of', 'the', 'national', 'football', 'league', 'nfl', 'for', 'the', 'twenty', 'fifteen', 'season', '.', 'the', 'american', 'football', 'conference', 'a', 'f', 'c', 'c', 'champion', 'denver', 'broncos', 'defeated', 'the', 'national', 'football', 'conference', 'n', 'f', 'c', 'c', 'champion', 'carolina', 'panthers', 'twenty', 'four', 'to', 'ten', 'to', 'earn', 'their', 'third', 'super', 'bowl', 'title', '.', 'the', 'game', 'was', 'played', 'on', 'february', 'seventh', 'twenty', 'sixteen', 'and', 'levi', '##s', 'stadium', 'in', 'the', 'san', 'francisco', 'bay', 'area', 'santa', 'clara', 'california', '.', 'as', 'this', 'was', 'the', 'fi', '##ft', '##ie', '##th', 'super', 'bowl', 'the', 'league', 'emphasized', 'the', 'golden', 'anniversary', 'with', 'various', 'goldstein', '##s', 'initiatives', 'as', 'well', 'as', 'temporarily', 'suspend', '##ing', 'the', 'tradition', 'of', 'naming', 'each', 'super', 'bowl', 'game', 'with', 'roman', 'nu', '##meral', '##s', 'under', 'which', 'they', 'gain', 'would', 'have', 'been', 'known', 'as', 'super', 'bowl', 'l', 'sell', 'that', 'the', 'logo', 'could', 'prominently', 'featured', 'the', 'arabic', 'nu', '##meral', '##s', 'fifty', '.', '[SEP]', 'which', 'nfl', 'team', 'represented', 'the', 'afc', 'at', 'super', 'bowl', '50', '?', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "Offsets:  [(0, 0), (0, 5), (6, 10), (11, 16), (17, 20), (21, 23), (24, 32), (33, 41), (42, 46), (47, 49), (50, 59), (60, 63), (64, 72), (73, 75), (76, 79), (80, 88), (89, 97), (98, 104), (105, 108), (109, 112), (113, 116), (117, 123), (124, 131), (132, 138), (138, 139), (140, 143), (144, 152), (153, 161), (162, 172), (173, 174), (175, 176), (177, 178), (179, 180), (181, 189), (190, 196), (197, 204), (205, 213), (214, 217), (218, 226), (227, 235), (236, 246), (247, 248), (249, 250), (251, 252), (253, 254), (255, 263), (264, 272), (273, 281), (282, 288), (289, 293), (294, 296), (297, 300), (301, 303), (304, 308), (309, 314), (315, 320), (321, 326), (327, 331), (332, 337), (337, 338), (339, 342), (343, 347), (348, 351), (352, 358), (359, 361), (362, 370), (371, 378), (379, 385), (386, 393), (394, 397), (398, 402), (402, 403), (404, 411), (412, 414), (415, 418), (419, 422), (423, 432), (433, 436), (437, 441), (442, 447), (448, 453), (454, 464), (464, 465), (466, 468), (469, 473), (474, 477), (478, 481), (482, 484), (484, 486), (486, 488), (488, 490), (491, 496), (497, 501), (502, 505), (506, 512), (513, 523), (524, 527), (528, 534), (535, 546), (547, 551), (552, 559), (560, 569), (569, 570), (571, 582), (583, 585), (586, 590), (591, 593), (594, 605), (606, 613), (613, 616), (617, 620), (621, 630), (631, 633), (634, 640), (641, 645), (646, 651), (652, 656), (657, 661), (662, 666), (667, 672), (673, 675), (675, 680), (680, 681), (682, 687), (688, 693), (694, 698), (699, 703), (704, 709), (710, 714), (715, 719), (720, 725), (726, 728), (729, 734), (735, 739), (740, 741), (742, 746), (747, 751), (752, 755), (756, 760), (761, 766), (767, 778), (779, 787), (788, 791), (792, 798), (799, 801), (801, 806), (806, 807), (808, 813), (813, 814), (0, 0), (0, 5), (6, 9), (10, 14), (15, 26), (27, 30), (31, 34), (35, 37), (38, 43), (44, 48), (49, 51), (51, 52), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]\n",
      "Attention Mask:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Special Tokens Mask:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Accessing the first record in train_encodings_fast\n",
    "encoding = valid_encodings[0]\n",
    "\n",
    "# Accessing the attributes of the encoding\n",
    "ids = encoding.ids\n",
    "tokens = encoding.tokens\n",
    "offsets = encoding.offsets\n",
    "attention_mask = encoding.attention_mask\n",
    "special_tokens_mask = encoding.special_tokens_mask\n",
    "\n",
    "# Printing the results\n",
    "print(\"IDs: \", ids)\n",
    "print(\"Tokens: \", tokens)\n",
    "print(\"Offsets: \", offsets)\n",
    "print(\"Attention Mask: \", attention_mask)\n",
    "print(\"Special Tokens Mask: \", special_tokens_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce7e6b-4913-4262-9211-6bc49fbedc37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2f92f122-c80f-49e8-975b-32a9968fb6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i, answer in enumerate(answers):\n",
    "        start_pos = max(0, answer['answer_start'])\n",
    "        end_pos = max(0, answer['answer_end'] - 1)\n",
    "        start_positions.append(encodings.char_to_token(i, start_pos))\n",
    "        end_positions.append(encodings.char_to_token(i, end_pos))\n",
    "\n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length\n",
    "\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "# add_token_positions(train_encodings, train_answers)\n",
    "add_token_positions(valid_encodings, valid_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e536eb2-809b-4966-a0a9-e02737a061dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34, 34, 34, 46, 46, 46, 79, 70, 34, 34]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_encodings['start_positions'][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "633cdbd3-7fe2-4dea-b085-885a867a9f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQuAD_Dataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, encodings):\n",
    "    self.encodings = encodings\n",
    "  def __getitem__(self, idx):\n",
    "    return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "  def __len__(self):\n",
    "    return len(self.encodings.input_ids)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5de72dec-a79f-460b-8fbe-03a9bcd444b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = SQuAD_Dataset(train_encodings)\n",
    "valid_dataset = SQuAD_Dataset(valid_encodings)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5e80800-ae76-4cad-957f-d50039bbc2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3090a47-7cc8-48c2-870f-897bba6575d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "\n",
    "model = BertForQuestionAnswering.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e7afe8a3-f08a-409d-939d-e7844177401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_contexts, valid_questions, valid_answers = read_data('spoken_test-v1.1.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35637e68-a6f9-48bc-a176-769947ca5a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check on the available device - use GPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f'Working on {device}')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f00ae34e-e32d-4c35-b374-c96de162249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0594d2dd-f17e-404c-a0a1-2664924f1284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sdulam/.local/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1:  81%|████████  | 1874/2320 [05:22<01:16,  5.81it/s, loss=1.34] IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 1: 100%|██████████| 2320/2320 [06:39<00:00,  5.81it/s, loss=0.979]\n",
      "Epoch 2: 100%|██████████| 2320/2320 [06:42<00:00,  5.77it/s, loss=1.49] \n",
      "Epoch 3: 100%|██████████| 2320/2320 [06:41<00:00,  5.78it/s, loss=0.402] \n",
      "Epoch 4: 100%|██████████| 2320/2320 [06:40<00:00,  5.79it/s, loss=0.481] \n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "N_EPOCHS = 4\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "  loop = tqdm(train_loader, leave=True)\n",
    "  for batch in loop:\n",
    "    optim.zero_grad()\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    loop.set_description(f'Epoch {epoch+1}')\n",
    "    loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f9aa2e1-80bd-416a-a123-50fc9f6ac1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2320/2320 [00:04<00:00, 521.53it/s]\n"
     ]
    }
   ],
   "source": [
    "loop = tqdm(train_loader, leave=True)\n",
    "for batch in loop:\n",
    "    optim.zero_grad()\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbdef8db-2d68-4943-835e-777569846c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 32, 125,  64,  30,  46,   6, 155], device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52430dad-9f1a-418d-96ed-bc7d5d5383f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_answers = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            loss = outputs[0]\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            start_logits, end_logits = outputs[1], outputs[2]\n",
    "            for i in range(len(start_logits)):\n",
    "                start_pred = torch.argmax(start_logits[i]).item()\n",
    "                end_pred = torch.argmax(end_logits[i]).item()\n",
    "                prediction = tokenizer.decode(input_ids[i][start_pred:end_pred+1])\n",
    "                all_predictions.append(prediction)\n",
    "                all_answers.append(tokenizer.decode(input_ids[i][start_positions[i]:end_positions[i]+1]))\n",
    "\n",
    "    f1 = compute_f1(all_predictions, all_answers)\n",
    "\n",
    "    return total_loss/len(dataloader), f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7819d97f-505f-421d-bdb5-8ff3ed0ab16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('DL/tokenizer_config.json',\n",
       " 'DL/special_tokens_map.json',\n",
       " 'DL/vocab.txt',\n",
       " 'DL/added_tokens.json',\n",
       " 'DL/tokenizer.json')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'DL'\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12b8466b-3a6e-4073-bc4b-e2295d225c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "\n",
    "# acc = []\n",
    "\n",
    "# for batch in tqdm(valid_loader):\n",
    "#   with torch.no_grad():\n",
    "#     input_ids = batch['input_ids'].to(device)\n",
    "#     attention_mask = batch['attention_mask'].to(device)\n",
    "#     start_true = batch['start_positions'].to(device)\n",
    "#     end_true = batch['end_positions'].to(device)\n",
    "    \n",
    "#     outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "#     start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "#     end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "#     acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
    "#     acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
    "\n",
    "# acc = sum(acc)/len(acc)\n",
    "\n",
    "# print(\"\\n\\nT/P\\tanswer_start\\tanswer_end\\n\")\n",
    "# for i in range(len(start_true)):\n",
    "#   print(f\"true\\t{start_true[i]}\\t{end_true[i]}\\n\"\n",
    "#         f\"pred\\t{start_pred[i]}\\t{end_pred[i]}\\n\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "83c8ae6a-9d82-4cbb-87bb-9d7e37972b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(context, question):\n",
    "  inputs = tokenizer.encode_plus(question, context, return_tensors='pt').to(device)\n",
    "  outputs = model(**inputs)\n",
    "  \n",
    "  answer_start = torch.argmax(outputs[0])  \n",
    "  answer_end = torch.argmax(outputs[1]) + 1 \n",
    "  \n",
    "  answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
    "  \n",
    "  return answer\n",
    "\n",
    "def normalize_text(s):\n",
    "  \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "  import string, re\n",
    "  def remove_articles(text):\n",
    "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "    return re.sub(regex, \" \", text)\n",
    "  def white_space_fix(text):\n",
    "    return \" \".join(text.split())\n",
    "  def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return \"\".join(ch for ch in text if ch not in exclude)\n",
    "  def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def exact_match(prediction, truth):\n",
    "    return bool(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "  pred_tokens = normalize_text(prediction).split()\n",
    "  truth_tokens = normalize_text(truth).split()\n",
    "  \n",
    "  # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "  if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "    return int(pred_tokens == truth_tokens)\n",
    "  \n",
    "  common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "  \n",
    "  # if there are no common tokens then f1 = 0\n",
    "  if len(common_tokens) == 0:\n",
    "    return 0\n",
    "  \n",
    "  prec = len(common_tokens) / len(pred_tokens)\n",
    "  rec = len(common_tokens) / len(truth_tokens)\n",
    "  \n",
    "  return round(2 * (prec * rec) / (prec + rec), 2)\n",
    "\n",
    "  \n",
    "def question_answer(context, question,answer):\n",
    "  prediction = get_prediction(context,question)\n",
    "  em_score = exact_match(prediction, answer)\n",
    "  f1_score = compute_f1(prediction, answer)\n",
    "\n",
    "  print(f'Question: {question}')\n",
    "  print(f'Prediction: {prediction}')\n",
    "  print(f'True Answer: {answer}')\n",
    "  print(f'Exact match: {em_score}')\n",
    "  print(f'F1 score: {f1_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41579384-20b0-447d-96f5-ea12d1fd50c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_contexts44, valid_questions44, valid_answers44 = read_data('spoken_test-v1.1_WER44.json')\n",
    "    \n",
    "# add_end_idx(valid_answers44, valid_contexts44)\n",
    "# valid_encodings44 = tokenizer(\n",
    "#     valid_contexts44,\n",
    "#     valid_questions44,\n",
    "#     truncation=True,\n",
    "#     padding=True,\n",
    "#     max_length=250,\n",
    "#     stride=doc_stride)\n",
    "# add_token_positions(valid_encodings44, valid_answers44)\n",
    "# valid_dataset44 = SQuAD_Dataset(valid_encodings44)\n",
    "# valid_loader44 = DataLoader(valid_dataset44, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c2bdc34b-d30c-4b05-8b21-d4e4faeb57ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 993/993 [00:55<00:00, 17.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5763\n",
      "WER: 1.9152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import jiwer\n",
    "\n",
    "model.eval()\n",
    "acc = []\n",
    "wer = []\n",
    "\n",
    "for batch in tqdm(valid_loader):\n",
    "    with torch.no_grad():\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
    "        \n",
    "        # Calculate WER\n",
    "        for i in range(len(start_true)):\n",
    "            true_text = tokenizer.decode(input_ids[i][start_true[i]:end_true[i]])\n",
    "            pred_text = tokenizer.decode(input_ids[i][start_pred[i]:end_pred[i]])\n",
    "            if true_text.strip() == \"\":\n",
    "                continue\n",
    "            wer.append(jiwer.wer(true_text, pred_text))\n",
    "            f1_scores.append(compute_f1(true_text, pred_text))\n",
    "        \n",
    "acc = sum(acc) / len(acc)\n",
    "wer = sum(wer) / len(wer)\n",
    "\n",
    "print(f'Accuracy: {acc:.4f}')\n",
    "print(f'WER: {wer:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "75eb6d9f-d419-415d-9a69-980b8bb2d8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5643\n"
     ]
    }
   ],
   "source": [
    "overall_f1_score = np.mean(f1_scores)\n",
    "print(f'F1 Score: {overall_f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a92d3e-5920-484a-b0eb-9bd8f3537f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c89c6055-1452-4119-a4e5-0341ed1bb09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2320/2320 [06:22<00:00,  6.07it/s, loss=0.0107] \n",
      "Epoch 2: 100%|██████████| 2320/2320 [06:23<00:00,  6.04it/s, loss=0.00976]\n",
      "Epoch 3: 100%|██████████| 2320/2320 [06:23<00:00,  6.04it/s, loss=0.0103] \n",
      "Epoch 4: 100%|██████████| 2320/2320 [06:23<00:00,  6.04it/s, loss=0.0096] \n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "N_EPOCHS = 4\n",
    "GRAD_ACCUM_STEPS = 4\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "  loop = tqdm(train_loader, leave=True)\n",
    "  epoch_loss = 0\n",
    "  for i, batch in enumerate(loop):\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    loss /= GRAD_ACCUM_STEPS\n",
    "    loss.backward()\n",
    "    epoch_loss += loss.item()\n",
    "    if (i + 1) % GRAD_ACCUM_STEPS == 0:\n",
    "      optim.step()\n",
    "      optim.zero_grad()\n",
    "\n",
    "    loop.set_description(f'Epoch {epoch+1}')\n",
    "    loop.set_postfix(loss=epoch_loss / (i+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f6020d3e-b97e-43f5-a890-d4dc2e70625c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 993/993 [00:53<00:00, 18.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 3.3698\n",
      "Validation Accuracy: 0.5640\n",
      "\n",
      "\n",
      "T/P\tanswer_start\tanswer_end\n",
      "\n",
      "true\t59\t59\n",
      "pred\t54\t54\n",
      "\n",
      "true\t59\t60\n",
      "pred\t54\t54\n",
      "\n",
      "true\t59\t59\n",
      "pred\t54\t54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "total_loss = 0\n",
    "acc = []\n",
    "\n",
    "for batch in tqdm(valid_loader):\n",
    "  with torch.no_grad():\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_true = batch['start_positions'].to(device)\n",
    "    end_true = batch['end_positions'].to(device)\n",
    "    \n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_true, end_positions=end_true)\n",
    "\n",
    "    loss = outputs[0]\n",
    "    total_loss += loss.item()\n",
    "\n",
    "    start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "    end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "    acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
    "    acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
    "\n",
    "acc = sum(acc)/len(acc)\n",
    "avg_loss = total_loss / len(valid_loader)\n",
    "\n",
    "print(f\"\\nValidation Loss: {avg_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "print(\"\\n\\nT/P\\tanswer_start\\tanswer_end\\n\")\n",
    "for i in range(len(start_true)):\n",
    "  print(f\"true\\t{start_true[i]}\\t{end_true[i]}\\n\"\n",
    "        f\"pred\\t{start_pred[i]}\\t{end_pred[i]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb38b76-ba3e-4103-b7bc-2520ae69359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "\n",
    "# acc = []\n",
    "\n",
    "# for batch in tqdm(valid_loader):\n",
    "#   with torch.no_grad():\n",
    "#     input_ids = batch['input_ids'].to(device)\n",
    "#     attention_mask = batch['attention_mask'].to(device)\n",
    "#     start_true = batch['start_positions'].to(device)\n",
    "#     end_true = batch['end_positions'].to(device)\n",
    "    \n",
    "#     outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "#     start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "#     end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "#     acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
    "#     acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
    "\n",
    "# acc = sum(acc)/len(acc)\n",
    "\n",
    "# print(\"\\n\\nT/P\\tanswer_start\\tanswer_end\\n\")\n",
    "# for i in range(len(start_true)):\n",
    "#   print(f\"true\\t{start_true[i]}\\t{end_true[i]}\\n\"\n",
    "#         f\"pred\\t{start_pred[i]}\\t{end_pred[i]}\\n\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7edba8-7f7a-4a63-9ab6-21da4a159dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c9808204-e850-4353-9aff-4df3a84b7609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_prediction(context, question):\n",
    "#   inputs = tokenizer.encode_plus(question, context, return_tensors='pt').to(device)\n",
    "#   outputs = model(**inputs)\n",
    "  \n",
    "#   answer_start = torch.argmax(outputs[0])  \n",
    "#   answer_end = torch.argmax(outputs[1]) + 1 \n",
    "  \n",
    "#   answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
    "  \n",
    "#   return answer\n",
    "\n",
    "# def normalize_text(s):\n",
    "#   \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "#   import string, re\n",
    "#   def remove_articles(text):\n",
    "#     regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "#     return re.sub(regex, \" \", text)\n",
    "#   def white_space_fix(text):\n",
    "#     return \" \".join(text.split())\n",
    "#   def remove_punc(text):\n",
    "#     exclude = set(string.punctuation)\n",
    "#     return \"\".join(ch for ch in text if ch not in exclude)\n",
    "#   def lower(text):\n",
    "#     return text.lower()\n",
    "\n",
    "#   return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "# def exact_match(prediction, truth):\n",
    "#     return bool(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "# def compute_f1(prediction, truth):\n",
    "#   pred_tokens = normalize_text(prediction).split()\n",
    "#   truth_tokens = normalize_text(truth).split()\n",
    "  \n",
    "#   # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "#   if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "#     return int(pred_tokens == truth_tokens)\n",
    "  \n",
    "#   common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "  \n",
    "#   # if there are no common tokens then f1 = 0\n",
    "#   if len(common_tokens) == 0:\n",
    "#     return 0\n",
    "  \n",
    "#   prec = len(common_tokens) / len(pred_tokens)\n",
    "#   rec = len(common_tokens) / len(truth_tokens)\n",
    "  \n",
    "#   return round(2 * (prec * rec) / (prec + rec), 2)\n",
    "\n",
    "  \n",
    "# def question_answer(context, question,answer):\n",
    "#   prediction = get_prediction(context,question)\n",
    "#   em_score = exact_match(prediction, answer)\n",
    "#   f1_score = compute_f1(prediction, answer)\n",
    "\n",
    "#   print(f'Question: {question}')\n",
    "#   print(f'Prediction: {prediction}')\n",
    "#   print(f'True Answer: {answer}')\n",
    "#   print(f'Exact match: {em_score}')\n",
    "#   print(f'F1 score: {f1_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c07457f3-c586-492b-a526-e419e788f281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 993/993 [00:55<00:00, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 1.1681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import jiwer\n",
    "\n",
    "model.eval()\n",
    "wer = []\n",
    "f1_scores=[]\n",
    "for batch in tqdm(valid_loader):\n",
    "    with torch.no_grad():\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "        \n",
    "        # Calculate WER\n",
    "        for i in range(len(start_true)):\n",
    "            true_text = tokenizer.decode(input_ids[i][start_true[i]:end_true[i]])\n",
    "            pred_text = tokenizer.decode(input_ids[i][start_pred[i]:end_pred[i]])\n",
    "            if true_text.strip() == \"\":\n",
    "                continue\n",
    "            wer.append(jiwer.wer(true_text, pred_text))\n",
    "            f1_scores.append(compute_f1(true_text, pred_text))\n",
    "            \n",
    "        \n",
    "wer = sum(wer) / len(wer)\n",
    "print(f'WER: {wer:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d5206226-851f-4147-9719-396a936030ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5982779567418316\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "overall_f1_score = np.mean(f1_scores)\n",
    "print(overall_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "afe29d22-18bb-4d69-9408-70f6683fc197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2320/2320 [06:35<00:00,  5.86it/s, loss=0.0088] \n",
      "Epoch 2: 100%|██████████| 2320/2320 [06:37<00:00,  5.84it/s, loss=0.0156]\n",
      "Epoch 3: 100%|██████████| 2320/2320 [06:37<00:00,  5.84it/s, loss=0.0114]\n",
      "Epoch 4: 100%|██████████| 2320/2320 [06:37<00:00,  5.84it/s, loss=0.00802]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "N_EPOCHS = 4\n",
    "GRAD_ACCUM_STEPS = 4\n",
    "MAX_GRAD_NORM = 1.0\n",
    "WARMUP_STEPS = 500\n",
    "T_TOTAL = len(train_loader) * N_EPOCHS // GRAD_ACCUM_STEPS\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optim, num_warmup_steps=WARMUP_STEPS, num_training_steps=T_TOTAL\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(loop):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss /= GRAD_ACCUM_STEPS\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        if (i + 1) % GRAD_ACCUM_STEPS == 0:\n",
    "            optim.step()\n",
    "            scheduler.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "        loop.set_description(f'Epoch {epoch+1}')\n",
    "        loop.set_postfix(loss=epoch_loss / (i+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cd9616e6-9e68-4ba9-98f2-ad3fe4b251d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 993/993 [00:55<00:00, 17.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.565395\n",
      "WER: 1.367479\n",
      "F1_Score: 0.611829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import jiwer\n",
    "\n",
    "model.eval()\n",
    "acc = []\n",
    "wer = []\n",
    "f1_scores=[]\n",
    "for batch in tqdm(valid_loader):\n",
    "    with torch.no_grad():\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
    "        \n",
    "        # Calculate WER\n",
    "        for i in range(len(start_true)):\n",
    "            true_text = tokenizer.decode(input_ids[i][start_true[i]:end_true[i]])\n",
    "            pred_text = tokenizer.decode(input_ids[i][start_pred[i]:end_pred[i]])\n",
    "            if true_text.strip() == \"\":\n",
    "                continue\n",
    "            wer.append(jiwer.wer(true_text, pred_text))\n",
    "            f1_scores.append(compute_f1(true_text, pred_text))\n",
    "        \n",
    "acc = sum(acc) / len(acc)\n",
    "wer = sum(wer) / len(wer)\n",
    "overall_f1_score = np.mean(f1_scores)\n",
    "print(f'Accuracy: {acc:.6f}')\n",
    "print(f'WER: {wer:.6f}')\n",
    "print(f'F1_Score: {overall_f1_score:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9ba51b84-4775-45cc-8464-0146eea8ce73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "T/P\tanswer_start\tanswer_end\n",
      "\n",
      "true\t59\t\t\t59\n",
      "pred\t59\t\t\t54\n",
      "true\t59\t\t\t60\n",
      "pred\t59\t\t\t54\n",
      "true\t59\t\t\t59\n",
      "pred\t59\t\t\t54\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\\nT/P\\tanswer_start\\tanswer_end\\n\")\n",
    "for i in range(len(start_true)):\n",
    "    print(f\"true\\t{start_true[i]}\\t\\t\\t{end_true[i]}\\n\"\n",
    "          f\"pred\\t{start_pred[i]}\\t\\t\\t{end_pred[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0c3627a7-a0ff-4b83-88be-bb24f4f34103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aadcd679-0a6b-4e68-9526-95f52182d753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| T/P   |   Answer Start |   Answer End |\n",
      "|-------+----------------+--------------|\n",
      "| True  |             59 |           59 |\n",
      "| Pred  |             59 |           54 |\n",
      "| True  |             59 |           60 |\n",
      "| Pred  |             59 |           54 |\n",
      "| True  |             59 |           59 |\n",
      "| Pred  |             59 |           54 |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare data for table\n",
    "data = []\n",
    "for i in range(len(start_true)):\n",
    "    data.append(['True', start_true[i], end_true[i]])\n",
    "    data.append(['Pred', start_pred[i], end_pred[i]])\n",
    "\n",
    "# Print table\n",
    "print(tabulate(data, headers=['T/P', 'Answer Start', 'Answer End'], tablefmt='orgtbl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec650f1-23e0-48dd-a890-d4ffc6e0b067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dbc533db-e581-4838-aea7-208aef22110a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/993 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'start_positions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 11\u001b[0m start_true \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstart_positions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m end_true \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_positions\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'start_positions'"
     ]
    }
   ],
   "source": [
    "import jiwer\n",
    "\n",
    "model.eval()\n",
    "acc = []\n",
    "wer = []\n",
    "f1_scores=[]\n",
    "for batch in tqdm(valid_loader):\n",
    "    with torch.no_grad():\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
    "        \n",
    "        # Calculate WER\n",
    "        for i in range(len(start_true)):\n",
    "            true_text = tokenizer.decode(input_ids[i][start_true[i]:end_true[i]])\n",
    "            pred_text = tokenizer.decode(input_ids[i][start_pred[i]:end_pred[i]])\n",
    "            if true_text.strip() == \"\":\n",
    "                continue\n",
    "            wer.append(jiwer.wer(true_text, pred_text))\n",
    "            f1_scores.append(compute_f1(true_text, pred_text))\n",
    "        \n",
    "acc = sum(acc) / len(acc)\n",
    "wer = sum(wer) / len(wer)\n",
    "overall_f1_score = np.mean(f1_scores)\n",
    "print(f'Accuracy: {acc:.6f}')\n",
    "print(f'WER: {wer:.6f}')\n",
    "print(f'F1_Score: {overall_f1_score:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f2b2b0-1309-4b41-a033-71a6b16fe399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
